<span id="markdown-mermaid" aria-hidden="true"
                    data-dark-mode-theme="dark"
                    data-light-mode-theme="default"
                    data-max-text-size="50000"></span>
                <h1 id="text-generation">Text generation</h1>
<p>Learn how to prompt a model to generate text.</p>
<p>With the OpenAI API, you can use a <a href="/docs/models">large language model</a> to generate text from a prompt, as you might using <a href="https://chatgpt.com">ChatGPT</a>. Models can generate almost any kind of text response—like code, mathematical equations, structured JSON data, or human-like prose.</p>
<p>Here's a simple example using the <a href="/docs/api-reference/responses">Responses API</a>, our recommended API for all new projects.</p>
<p>Generate text from a simple prompt</p>
<pre><code class="language-javascript"><span class="hljs-keyword">import</span> <span class="hljs-title class_">OpenAI</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;openai&quot;</span>;
<span class="hljs-keyword">const</span> client = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OpenAI</span>();

<span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> client.<span class="hljs-property">responses</span>.<span class="hljs-title function_">create</span>({
    <span class="hljs-attr">model</span>: <span class="hljs-string">&quot;gpt-5&quot;</span>,
    <span class="hljs-attr">input</span>: <span class="hljs-string">&quot;Write a one-sentence bedtime story about a unicorn.&quot;</span>
});

<span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(response.<span class="hljs-property">output_text</span>);
</code></pre>
<pre><code class="language-python"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
client = OpenAI()

response = client.responses.create(
    model=<span class="hljs-string">&quot;gpt-5&quot;</span>,
    <span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;Write a one-sentence bedtime story about a unicorn.&quot;</span>
)

<span class="hljs-built_in">print</span>(response.output_text)
</code></pre>
<pre><code class="language-csharp"><span class="hljs-keyword">using</span> OpenAI.Responses;

<span class="hljs-built_in">string</span> key = Environment.GetEnvironmentVariable(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>)!;
OpenAIResponseClient client = <span class="hljs-keyword">new</span>(model: <span class="hljs-string">&quot;gpt-5&quot;</span>, apiKey: key);

OpenAIResponse response = client.CreateResponse(
    <span class="hljs-string">&quot;Write a one-sentence bedtime story about a unicorn.&quot;</span>
);

Console.WriteLine(response.GetOutputText());
</code></pre>
<pre><code class="language-bash">curl <span class="hljs-string">&quot;https://api.openai.com/v1/responses&quot;</span> \
    -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \
    -H <span class="hljs-string">&quot;Authorization: Bearer <span class="hljs-variable">$OPENAI_API_KEY</span>&quot;</span> \
    -d <span class="hljs-string">&#x27;{
        &quot;model&quot;: &quot;gpt-5&quot;,
        &quot;input&quot;: &quot;Write a one-sentence bedtime story about a unicorn.&quot;
    }&#x27;</span>
</code></pre>
<p>An array of content generated by the model is in the <code>output</code> property of the response. In this simple example, we have just one output which looks like this:</p>
<pre><code class="language-json"><span class="hljs-punctuation">[</span>
    <span class="hljs-punctuation">{</span>
        <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;msg_67b73f697ba4819183a15cc17d011509&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;message&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
            <span class="hljs-punctuation">{</span>
                <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;output_text&quot;</span><span class="hljs-punctuation">,</span>
                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Under the soft glow of the moon, Luna the unicorn danced through fields of twinkling stardust, leaving trails of dreams for every child asleep.&quot;</span><span class="hljs-punctuation">,</span>
                <span class="hljs-attr">&quot;annotations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span>
            <span class="hljs-punctuation">}</span>
        <span class="hljs-punctuation">]</span>
    <span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">]</span>
</code></pre>
<p><strong>The <code>output</code> array often has more than one item in it!</strong> It can contain tool calls, data about reasoning tokens generated by <a href="/docs/guides/reasoning">reasoning models</a>, and other items. It is not safe to assume that the model's text output is present at <code>output[0].content[0].text</code>.</p>
<p>Some of our <a href="/docs/libraries">official SDKs</a> include an <code>output_text</code> property on model responses for convenience, which aggregates all text outputs from the model into a single string. This may be useful as a shortcut to access text output from the model.</p>
<p>In addition to plain text, you can also have the model return structured data in JSON format—this feature is called <a href="/docs/guides/structured-outputs"><strong>Structured Outputs</strong></a>.</p>
<h2 id="prompt-engineering">Prompt engineering</h2>
<p><strong>Prompt engineering</strong> is the process of writing effective instructions for a model, such that it consistently generates content that meets your requirements.</p>
<p>Because the content generated from a model is non-deterministic, prompting to get your desired output is a mix of art and science. However, you can apply techniques and best practices to get good results consistently.</p>
<p>Some prompt engineering techniques work with every model, like using message roles. But different models might need to be prompted differently to produce the best results. Even different snapshots of models within the same family could produce different results. So as you build more complex applications, we strongly recommend:</p>
<ul>
<li>Pinning your production applications to specific <a href="/docs/models">model snapshots</a> (like <code>gpt-5-2025-08-07</code> for example) to ensure consistent behavior</li>
<li>Building <a href="/docs/guides/evals">evals</a> that measure the behavior of your prompts so you can monitor prompt performance as you iterate, or when you change and upgrade model versions</li>
</ul>
<p>Now, let's examine some tools and techniques available to you to construct prompts.</p>
<h2 id="choosing-models-and-apis">Choosing models and APIs</h2>
<p>OpenAI has many different <a href="/docs/models">models</a> and several APIs to choose from. <a href="/docs/guides/reasoning">Reasoning models</a>, like o3 and GPT-5, behave differently from chat models and respond better to different prompts. One important note is that reasoning models perform better and demonstrate higher intelligence when used with the Responses API.</p>
<p>If you're building any text generation app, we recommend using the Responses API over the older Chat Completions API. And if you're using a reasoning model, it's especially useful to <a href="/docs/guides/migrate-to-responses">migrate to Responses</a>.</p>
<h2 id="message-roles-and-instruction-following">Message roles and instruction following</h2>
<p>You can provide instructions to the model with <a href="https://model-spec.openai.com/2025-02-12.html#chain_of_command">differing levels of authority</a> using the <code>instructions</code> API parameter along with <strong>message roles</strong>.</p>
<p>The <code>instructions</code> parameter gives the model high-level instructions on how it should behave while generating a response, including tone, goals, and examples of correct responses. Any instructions provided this way will take priority over a prompt in the <code>input</code> parameter.</p>
<p>Generate text with instructions</p>
<pre><code class="language-javascript"><span class="hljs-keyword">import</span> <span class="hljs-title class_">OpenAI</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;openai&quot;</span>;
<span class="hljs-keyword">const</span> client = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OpenAI</span>();

<span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> client.<span class="hljs-property">responses</span>.<span class="hljs-title function_">create</span>({
    <span class="hljs-attr">model</span>: <span class="hljs-string">&quot;gpt-5&quot;</span>,
    <span class="hljs-attr">reasoning</span>: { <span class="hljs-attr">effort</span>: <span class="hljs-string">&quot;low&quot;</span> },
    <span class="hljs-attr">instructions</span>: <span class="hljs-string">&quot;Talk like a pirate.&quot;</span>,
    <span class="hljs-attr">input</span>: <span class="hljs-string">&quot;Are semicolons optional in JavaScript?&quot;</span>,
});

<span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(response.<span class="hljs-property">output_text</span>);
</code></pre>
<pre><code class="language-python"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
client = OpenAI()

response = client.responses.create(
    model=<span class="hljs-string">&quot;gpt-5&quot;</span>,
    reasoning={<span class="hljs-string">&quot;effort&quot;</span>: <span class="hljs-string">&quot;low&quot;</span>},
    instructions=<span class="hljs-string">&quot;Talk like a pirate.&quot;</span>,
    <span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;Are semicolons optional in JavaScript?&quot;</span>,
)

<span class="hljs-built_in">print</span>(response.output_text)
</code></pre>
<pre><code class="language-bash">curl <span class="hljs-string">&quot;https://api.openai.com/v1/responses&quot;</span> \
    -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \
    -H <span class="hljs-string">&quot;Authorization: Bearer <span class="hljs-variable">$OPENAI_API_KEY</span>&quot;</span> \
    -d <span class="hljs-string">&#x27;{
        &quot;model&quot;: &quot;gpt-5&quot;,
        &quot;reasoning&quot;: {&quot;effort&quot;: &quot;low&quot;},
        &quot;instructions&quot;: &quot;Talk like a pirate.&quot;,
        &quot;input&quot;: &quot;Are semicolons optional in JavaScript?&quot;
    }&#x27;</span>
</code></pre>
<p>The example above is roughly equivalent to using the following input messages in the <code>input</code> array:</p>
<p>Generate text with messages using different roles</p>
<pre><code class="language-javascript"><span class="hljs-keyword">import</span> <span class="hljs-title class_">OpenAI</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;openai&quot;</span>;
<span class="hljs-keyword">const</span> client = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OpenAI</span>();

<span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> client.<span class="hljs-property">responses</span>.<span class="hljs-title function_">create</span>({
    <span class="hljs-attr">model</span>: <span class="hljs-string">&quot;gpt-5&quot;</span>,
    <span class="hljs-attr">reasoning</span>: { <span class="hljs-attr">effort</span>: <span class="hljs-string">&quot;low&quot;</span> },
    <span class="hljs-attr">input</span>: [
        {
            <span class="hljs-attr">role</span>: <span class="hljs-string">&quot;developer&quot;</span>,
            <span class="hljs-attr">content</span>: <span class="hljs-string">&quot;Talk like a pirate.&quot;</span>
        },
        {
            <span class="hljs-attr">role</span>: <span class="hljs-string">&quot;user&quot;</span>,
            <span class="hljs-attr">content</span>: <span class="hljs-string">&quot;Are semicolons optional in JavaScript?&quot;</span>,
        },
    ],
});

<span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(response.<span class="hljs-property">output_text</span>);
</code></pre>
<pre><code class="language-python"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
client = OpenAI()

response = client.responses.create(
    model=<span class="hljs-string">&quot;gpt-5&quot;</span>,
    reasoning={<span class="hljs-string">&quot;effort&quot;</span>: <span class="hljs-string">&quot;low&quot;</span>},
    <span class="hljs-built_in">input</span>=[
        {
            <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;developer&quot;</span>,
            <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Talk like a pirate.&quot;</span>
        },
        {
            <span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>,
            <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;Are semicolons optional in JavaScript?&quot;</span>
        }
    ]
)

<span class="hljs-built_in">print</span>(response.output_text)
</code></pre>
<pre><code class="language-bash">curl <span class="hljs-string">&quot;https://api.openai.com/v1/responses&quot;</span> \
    -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \
    -H <span class="hljs-string">&quot;Authorization: Bearer <span class="hljs-variable">$OPENAI_API_KEY</span>&quot;</span> \
    -d <span class="hljs-string">&#x27;{
        &quot;model&quot;: &quot;gpt-5&quot;,
        &quot;reasoning&quot;: {&quot;effort&quot;: &quot;low&quot;},
        &quot;input&quot;: [
            {
                &quot;role&quot;: &quot;developer&quot;,
                &quot;content&quot;: &quot;Talk like a pirate.&quot;
            },
            {
                &quot;role&quot;: &quot;user&quot;,
                &quot;content&quot;: &quot;Are semicolons optional in JavaScript?&quot;
            }
        ]
    }&#x27;</span>
</code></pre>
<p>Note that the <code>instructions</code> parameter only applies to the current response generation request. If you are <a href="/docs/guides/conversation-state">managing conversation state</a> with the <code>previous_response_id</code> parameter, the <code>instructions</code> used on previous turns will not be present in the context.</p>
<p>The <a href="https://model-spec.openai.com/2025-02-12.html#chain_of_command">OpenAI model spec</a> describes how our models give different levels of priority to messages with different roles.</p>
<table>
<thead>
<tr>
<th>developer</th>
<th>user</th>
<th>assistant</th>
</tr>
</thead>
<tbody>
<tr>
<td>developer messages are instructions provided by the application developer, prioritized ahead of user messages.</td>
<td>user messages are instructions provided by an end user, prioritized behind developer messages.</td>
<td>Messages generated by the model have the assistant role.</td>
</tr>
</tbody>
</table>
<p>A multi-turn conversation may consist of several messages of these types, along with other content types provided by both you and the model. Learn more about <a href="/docs/guides/conversation-state">managing conversation state here</a>.</p>
<p>You could think about <code>developer</code> and <code>user</code> messages like a function and its arguments in a programming language.</p>
<ul>
<li><code>developer</code> messages provide the system's rules and business logic, like a function definition.</li>
<li><code>user</code> messages provide inputs and configuration to which the <code>developer</code> message instructions are applied, like arguments to a function.</li>
</ul>
<h2 id="reusable-prompts">Reusable prompts</h2>
<p>In the OpenAI dashboard, you can develop reusable <a href="/chat/edit">prompts</a> that you can use in API requests, rather than specifying the content of prompts in code. This way, you can more easily build and evaluate your prompts, and deploy improved versions of your prompts without changing your integration code.</p>
<p>Here's how it works:</p>
<ol>
<li><strong>Create a reusable prompt</strong> in the <a href="/chat/edit">dashboard</a> with placeholders like <code>{{customer_name}}</code>.</li>
<li><strong>Use the prompt</strong> in your API request with the <code>prompt</code> parameter. The prompt parameter object has three properties you can configure:
<ul>
<li><code>id</code> — Unique identifier of your prompt, found in the dashboard</li>
<li><code>version</code> — A specific version of your prompt (defaults to the &quot;current&quot; version as specified in the dashboard)</li>
<li><code>variables</code> — A map of values to substitute in for variables in your prompt. The substitution values can either be strings, or other Response input message types like <code>input_image</code> or <code>input_file</code>. <a href="/docs/api-reference/responses/create">See the full API reference</a>.</li>
</ul>
</li>
</ol>
<p>String variables</p>
<p>Generate text with a prompt template</p>
<pre><code class="language-javascript"><span class="hljs-keyword">import</span> <span class="hljs-title class_">OpenAI</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;openai&quot;</span>;
<span class="hljs-keyword">const</span> client = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OpenAI</span>();

<span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> client.<span class="hljs-property">responses</span>.<span class="hljs-title function_">create</span>({
    <span class="hljs-attr">model</span>: <span class="hljs-string">&quot;gpt-5&quot;</span>,
    <span class="hljs-attr">prompt</span>: {
        <span class="hljs-attr">id</span>: <span class="hljs-string">&quot;pmpt_abc123&quot;</span>,
        <span class="hljs-attr">version</span>: <span class="hljs-string">&quot;2&quot;</span>,
        <span class="hljs-attr">variables</span>: {
            <span class="hljs-attr">customer_name</span>: <span class="hljs-string">&quot;Jane Doe&quot;</span>,
            <span class="hljs-attr">product</span>: <span class="hljs-string">&quot;40oz juice box&quot;</span>
        }
    }
});

<span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(response.<span class="hljs-property">output_text</span>);
</code></pre>
<pre><code class="language-python"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
client = OpenAI()

response = client.responses.create(
    model=<span class="hljs-string">&quot;gpt-5&quot;</span>,
    prompt={
        <span class="hljs-string">&quot;id&quot;</span>: <span class="hljs-string">&quot;pmpt_abc123&quot;</span>,
        <span class="hljs-string">&quot;version&quot;</span>: <span class="hljs-string">&quot;2&quot;</span>,
        <span class="hljs-string">&quot;variables&quot;</span>: {
            <span class="hljs-string">&quot;customer_name&quot;</span>: <span class="hljs-string">&quot;Jane Doe&quot;</span>,
            <span class="hljs-string">&quot;product&quot;</span>: <span class="hljs-string">&quot;40oz juice box&quot;</span>
        }
    }
)

<span class="hljs-built_in">print</span>(response.output_text)
</code></pre>
<pre><code class="language-bash">curl https://api.openai.com/v1/responses \
  -H <span class="hljs-string">&quot;Authorization: Bearer <span class="hljs-variable">$OPENAI_API_KEY</span>&quot;</span> \
  -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \
  -d <span class="hljs-string">&#x27;{
    &quot;model&quot;: &quot;gpt-5&quot;,
    &quot;prompt&quot;: {
      &quot;id&quot;: &quot;pmpt_abc123&quot;,
      &quot;version&quot;: &quot;2&quot;,
      &quot;variables&quot;: {
        &quot;customer_name&quot;: &quot;Jane Doe&quot;,
        &quot;product&quot;: &quot;40oz juice box&quot;
      }
    }
  }&#x27;</span>
</code></pre>
<p>Variables with file input</p>
<p>Prompt template with file input variable</p>
<pre><code class="language-javascript"><span class="hljs-keyword">import</span> fs <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;fs&quot;</span>;
<span class="hljs-keyword">import</span> <span class="hljs-title class_">OpenAI</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&quot;openai&quot;</span>;
<span class="hljs-keyword">const</span> client = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OpenAI</span>();

<span class="hljs-comment">// Upload a PDF we will reference in the prompt variables</span>
<span class="hljs-keyword">const</span> file = <span class="hljs-keyword">await</span> client.<span class="hljs-property">files</span>.<span class="hljs-title function_">create</span>({
    <span class="hljs-attr">file</span>: fs.<span class="hljs-title function_">createReadStream</span>(<span class="hljs-string">&quot;draconomicon.pdf&quot;</span>),
    <span class="hljs-attr">purpose</span>: <span class="hljs-string">&quot;user_data&quot;</span>,
});

<span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> client.<span class="hljs-property">responses</span>.<span class="hljs-title function_">create</span>({
    <span class="hljs-attr">model</span>: <span class="hljs-string">&quot;gpt-5&quot;</span>,
    <span class="hljs-attr">prompt</span>: {
        <span class="hljs-attr">id</span>: <span class="hljs-string">&quot;pmpt_abc123&quot;</span>,
        <span class="hljs-attr">variables</span>: {
            <span class="hljs-attr">topic</span>: <span class="hljs-string">&quot;Dragons&quot;</span>,
            <span class="hljs-attr">reference_pdf</span>: {
                <span class="hljs-attr">type</span>: <span class="hljs-string">&quot;input_file&quot;</span>,
                <span class="hljs-attr">file_id</span>: file.<span class="hljs-property">id</span>,
            },
        },
    },
});

<span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(response.<span class="hljs-property">output_text</span>);
</code></pre>
<pre><code class="language-python"><span class="hljs-keyword">import</span> openai, pathlib

client = openai.OpenAI()

<span class="hljs-comment"># Upload a PDF we will reference in the variables</span>
file = client.files.create(
    file=<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;draconomicon.pdf&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>),
    purpose=<span class="hljs-string">&quot;user_data&quot;</span>,
)

response = client.responses.create(
    model=<span class="hljs-string">&quot;gpt-5&quot;</span>,
    prompt={
        <span class="hljs-string">&quot;id&quot;</span>: <span class="hljs-string">&quot;pmpt_abc123&quot;</span>,
        <span class="hljs-string">&quot;variables&quot;</span>: {
            <span class="hljs-string">&quot;topic&quot;</span>: <span class="hljs-string">&quot;Dragons&quot;</span>,
            <span class="hljs-string">&quot;reference_pdf&quot;</span>: {
                <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;input_file&quot;</span>,
                <span class="hljs-string">&quot;file_id&quot;</span>: file.<span class="hljs-built_in">id</span>,
            },
        },
    },
)

<span class="hljs-built_in">print</span>(response.output_text)
</code></pre>
<pre><code class="language-bash"><span class="hljs-comment"># Assume you have already uploaded the PDF and obtained FILE_ID</span>
curl https://api.openai.com/v1/responses   -H <span class="hljs-string">&quot;Authorization: Bearer <span class="hljs-variable">$OPENAI_API_KEY</span>&quot;</span>   -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span>   -d <span class="hljs-string">&#x27;{
    &quot;model&quot;: &quot;gpt-5&quot;,
    &quot;prompt&quot;: {
      &quot;id&quot;: &quot;pmpt_abc123&quot;,
      &quot;variables&quot;: {
        &quot;topic&quot;: &quot;Dragons&quot;,
        &quot;reference_pdf&quot;: {
          &quot;type&quot;: &quot;input_file&quot;,
          &quot;file_id&quot;: &quot;file-abc123&quot;
        }
      }
    }
  }&#x27;</span>
</code></pre>
<h2 id="next-steps">Next steps</h2>
<p>Now that you known the basics of text inputs and outputs, you might want to check out one of these resources next.</p>
<p>[</p>
<p>Build a prompt in the Playground</p>
<p>Use the Playground to develop and iterate on prompts.</p>
<p>](/chat/edit)[</p>
<p>Generate JSON data with Structured Outputs</p>
<p>Ensure JSON data emitted from a model conforms to a JSON schema.</p>
<p>](/docs/guides/structured-outputs)[</p>
<p>Full API reference</p>
<p>Check out all the options for text generation in the API reference.</p>
<p>](/docs/api-reference/responses)</p>
